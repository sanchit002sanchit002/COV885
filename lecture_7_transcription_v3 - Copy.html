<!DOCTYPE html>
<html lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
	<title>Lecture 7 Transcript</title>
	<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans+SC:300,400,700' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" href="styles.css" />
</head>
<body>

<div class="center">
<h1 id="conversion-wrap-up-and-other-formats">Conversion wrap-up and Other Formats</h1>
<h1 id="dr.-volker-sorge"><a href="https://www.cs.bham.ac.uk/~vxs/index.php">Dr. Volker Sorge</a></h1>
</div>
<p class="arialFont"><a href="http://htmlpreview.github.io/?https://github.com/zorkow/COV885/blob/main/lecture_07/index.html">Lecture slides</a></p>
<h1 id="overview">Overview</h1>
<p class="arialFont">Welcome back. What I want to do today is, first of all, I kind of given a loosely formulated homework last time, so I would like to see what people came up with, trying to tie up some of the ends with the math conversion and particular document conversion of math document for LaTeX and other sources. And then we are going to have a look at some of the other documents that we haven't really discussed, things coming from images, PDFs(generating PDFs), also talk tiny bit about EPUB files that will then kind of close on this major section of the lecture and then next lecture (tomorrow) will then start with graphics primarily' kind of artefacts and documents in particular stem documents.<br />
Okay! So, my 1st question is, to all of you, so has anybody had got a chance to look into the SVG formulas that I had posted, that were there on the repository! So have you had a time to Play around with it? If you have, would you like to share what you have done.<br />
What I said last time was, It is a good idea to just take SVG and add different kind of Tab indices, You change the order of the elements, around which you tab through… And so on… That kind of give you more of a feeling what you can do and in a particular what the flexibilities are with these structures.<br />
To the next one, has anybody looked into the maths documents which we have converted.<br />
- <a href="https://github.com/zorkow/COV885/raw/main/exercises/math_example/rademacher_2013-12-16.pdf">original PDF</a></p>
<ul class="incremental">
<li><a href="http://htmlpreview.github.io/?https://github.com/zorkow/COV885/blob/main/exercises/math_example/rademacher_pd.html">pandoc conversion</a></li>
<li><a href="http://htmlpreview.github.io/?https://github.com/zorkow/COV885/blob/main/exercises/math_example/rademacher_mk.html">make4ht conversion</a></li>
</ul>
<p class="arialFont">Question:<br />
where are you going to put footnotes on a document which does not separated into pages. If you have no page breaks. I suppose the end of the document is as good as any. Similar to Wikipedia articles (references etcetera), all you have is at the end of the document. What do you think, Is it important for footnotes or references of that nature.<br />
In documents, it is always a good practice to having a back links for the references. It's pandoc which tries to include those back links.<br />
some of the points where bibliographies are missing, the referencing, footnotes, figures are broken etc.</p>
<h1 id="tweaking-converters-pandoc">Tweaking Converters: pandoc</h1>
<p class="arialFont">All of these things in many ways can be fixed. By working more diligently with conversion tools. Pandoc has many ways to tweak the converter. What is called "Pandoc Filters" which are effectively post processors. Which you can use in order to improve your output.</p>
<h2 id="github-search"><a href="https://github.com/topics/pandoc-filter">github search</a></h2>
<p class="arialFont">If we do a general search on github for pandoc filters you will come across more than 70 repositories.</p>
<h2 id="pandoc-crossref"><a href="https://github.com/lierdakil/pandoc-crossref">pandoc-crossref</a></h2>
<p class="arialFont">This will help you with cross-referencing. This is all for doing clever things with latex packages for clever referencing.</p>
<h2 id="pandoc-xnos"><a href="https://github.com/tomduck/pandoc-xnos">pandoc-xnos</a></h2>
<p class="arialFont">This is particularly used if you have equation numbering, referencing for equation numbering, table numbering, figure numbers etc. you get automatically links between these elements.</p>
<h2 id="mermaid-filter"><a href="https://github.com/raghur/mermaid-filter">mermaid-filter</a></h2>
<h2 id="lua-filters"><a href="https://github.com/pandoc/lua-filters">Lua filters</a></h2>
<p class="arialFont">pandoc supports lua filters.<br />
What are lua filters?<br />
Lua itself is a lightweight scripting language. Which is built on top of C or C++. The whole Paradigm of Lua is it allows you to do postprocessing on data structures, also intermediate postprocessing on data structures. With just few scripting markups.<br />
pandoc has entire collection of lua Filters. Which not only gives us a very easy way of including tiny scripts to just tweak the occasional command, or the output of the occasional latex command. But also allows us to create our own filters. For instance citations, short section referencing, for captioning, for all kinds of things.<br />
   pandoc –filter=PROGRAM …</p>
<p class="arialFont">All of these filters are there, that means you have to select what you want and then what are your needs of the particular document, depending on what packages authors have used, you might need different filters. There is a lot of potential for extensions. But it always has to do bit of research what you need for a particular document. For all of the issues that now you have identified in the document, there will be some sort of filter which can take care of it. Obviously there will be some documents which always be so complex and complicated that you might not find a yet another filter for it. Which solves all the problems.</p>
<h1 id="tweaking-converters-pmake4ht">Tweaking Converters: pmake4ht</h1>
<p class="arialFont">make4ht has advantage that you can use multiple backends.<br />
The one which is shown above<a href="http://htmlpreview.github.io/?https://github.com/zorkow/COV885/blob/main/exercises/math_example/rademacher_mk.html">make4ht conversion</a> is tex4ht which is effectively a backend which works with normal latex contribution. tex4ht is not that easy to tweak. Things like Texlive, dTeX, Miktex for windows…<br />
One in particular luatex, it has an idea of having a lua style scripting language built in, meaning you can easily enter commands in TeX, depending on what you need as a output.. It is a principal way to add a lightweight scripting to TeX, that can be particularly exploited for conversion using a backend for make4ht using lua4ht and luaTeX. (Postconversion filtering and processing for output)</p>
<h1 id="bibliographies-and-citations">Bibliographies and Citations</h1>
<p class="arialFont">In bibliographies and citations there is a very good tooling support.<br />
if you download <a href="https://github.com/zorkow/COV885/raw/main/exercises/math_example.zip">this zip file</a>, there is a bibliography file included, so if you could do the conversion by yourself, by means use the bibliography file and it should be included.<br />
  </p>
<p class="arialFont">\begin{bibliography}</p>
<ul class="incremental">
<li>Bibtex is generally ok.</li>
<li>Other tooling has less support (natbib, biblatex, biber)</li>
<li>citations should match cross-references and bibliography</li>
<li>Backlinks are good, and not just for accessibility, backlinks are always good.<br />
</li>
<li>pandoc adds backlinks automatically, <a href="https://tex.stackexchange.com/questions/521644/tex4ht-backref-option-of-hyperref-not-working-well">tex4ht</a> is not that well supported for backlinks.</li>
<li>advanced markup (DPUB ARIA, schema.org) not supported by conversion</li>
</ul>
<h1 id="cross-references.">Cross-references.</h1>
<p class="arialFont">Cross-referencing is the whole point for web. You want to reference everywhere and anywhere every time. In many ways referencing is a good thing. But it has to be done right. Sometimes authors particularly don't do it very well. Meaning they do all kinds of clever things such as abbreviations for references and that's one of things you have to get rid of it manually sometimes.<br />
For instance, never reference a range of elements. e.g. Reference 1 to 8, i.e.</p>
<pre><code>\ref{1} -- \ref{8}
</code></pre>
<h1 id="footnotes">Footnotes</h1>
<p class="arialFont">The best thing is always avoid footnotes. My general advice is if you put something in footnote think about how important it actually is,<br />
if something is really important for the understanding of the content then it shouldn't be in the footnotes. Even if there's just an explanation of abbreviation or something… In my opinion that should always be right in the text. In very very few occasions where you need footnote.<br />
There are certain citation styles, particularly in social sciences, where footnotes is kind of the main means of introducing citations. That obviously you will not really want on web. And if you do want it on web then we do Wikipedia style. That's pretty much main way to do it.</p>
<h1 id="indices-glossaries-appendices">Indices, Glossaries, Appendices</h1>
<p class="arialFont">Appendices are easy, they normally works like a sections. ARIA markup for appendices is usually not supported by convertors (but little impact in practice).<br />
Indices in the web documents are rarely used. If you want to do it, then you do more like a navigation element of that page. Normally web indices are on the left-hand side like a navigation bar.<br />
Glossaries in general, becomes very unfashionable, yes if you have a big book, for those instance glossaries are useful. But in most writings glossaries can easily outsourced. You rather use the power of web which is given to you like linking Wikipedia links etc.<br />
</p>
<h1 id="theorem-environments">Theorem Environments</h1>
<p class="arialFont">What are things like theorem environments and proof environments.<br />
Generally TeX converters do not treat these things very well. (just creating wrapping divs); Sometimes they do work when it is not nastily nested so post-processing might be feasible. But some authors and environments do nest it heavily then it becomes difficult.<br />
  <sub>QUOTE</sub> don't nest, don't abuse</p>
<p class="arialFont">what are they really? Landmarks?<br />
You should always think about these kind of environments in terms of what really they are. In many ways they are not much different than sections. a theorem is something which is kind of small paragraph with the heading, it's more something which you want to treate like landmark (with identifiable titles) and as you read any other section or paragraph or some other elements in a page. we lack a dedicated native solution, but can do e.g., section+heading, figure+figcaption, possibly with a role description.<br />
PreTeXt is a way to getting math document on to the web, particularly in open format. checkout <a href="https://github.com/oscarlevin/pandoc-pretext">pandoc-pretext</a><br />
amsthm advice for proofs: short = theorem, long = section<br />
e.g., don't do subclaims in proofs as theorems just because you like the styling</p>
<h1 id="algorithm-layout">Algorithm Layout</h1>
<p class="arialFont">In computer science books or articles, algorithm layout is something which is generally badly supported, when it comes to converting elements. There are various ways how to do this, for instance, one of system is <a href="https://prismjs.com/">prism js</a>, which allows you to include raw source code into html elements. Alternative solution is to do something with Markdown elements. Markdown elements gives you a nice way of including source code. My general advice, when it comes to converting content which contains lots of algorithms, try to identify where the algorithms are, get them out and put them in spoken environment or spoken system which can work with markdown. <a href="https://prismjs.com/">Prism js</a> is also one of them which actually allows you to easily work with these algorithm content.</p>
<h1 id="diagram-authoring">Diagram Authoring</h1>
<p class="arialFont">One of the things which we saw in our example document was… Some of the images didn't come across well… Some of the images either omitted… or they were at wrong size, all that has to do is of course with diagram authoring! But that's something which we will start tomorrow. How will make them accessible in particular.</p>
<h1 id="considerations-in-latex-authoring">Considerations in LaTeX Authoring</h1>
<p class="arialFont">If you are author yourself or if you also work with authors, want to educate authors in particular what is good and what is bad in terms of authoring, when you need to convert something into accessible format.<br />
In various American universities, where department puts together guidelines, for their staff and for their faculty in particular. How they should write their documents, what they should avoid in documents in order to make the life easier for those who sits in places where they have to convert it and make it accessible.<br />
</p>
<h2 id="tex-tips-what-to-do">TeX tips: what to do</h2>
<p class="arialFont">One of the classic advice is always try to pick common latex style. It's like a programming. There are so many ways how you can program and how you can structure your code well and how you can structure your code badly.<br />
</p>
<ul class="incremental">
<li><a href="https://en.wikibooks.org/wiki/LaTeX">Wikibook LaTeX</a></li>
<li><a href="https://texdoc.org/serve/latex2e.pdf/0">LaTeX 2e Unofficial Manual</a></li>
<li><a href="https://www.ams.org/publications/authors/AMS-StyleGuide-online.pdf">AMS Style Guide</a></li>
</ul>
<p class="arialFont">How you can document your code well and how you can leave your code entirely undocumented for instance. The same thing holds for latex. Hence there are plenty of style guides out there. There are all kinds of ways how to do standard sectioning, lists, figures, use labels and cross-reference them (\ref, \cite etc) And So on…<br />
   <span class="math inline">$\eqref$</span></p>
<p class="arialFont">can help with pass through.</p>
<h1 id="things-that-you-should-always-avoid-in-latex">Things that you should always avoid in latex</h1>
<ol class="incremental">
<li>plain TeX - LaTeX only please!</li>
<li>TeX programming (changing core macros, active characters, loops etc)</li>
<li><a href="https://mirror.clientvps.com/CTAN/info/l2tabu/english/l2tabuen.pdf">LaTeX taboos</a></li>
<li>box hackery, e.g., parbox, minipage, pbox, fbox, raisebox, rotatebox</li>
<li>Using real world page dimensions ( etc), Never use things such as inches millimetre centimetre. Always talk in terms of em and px, the relative size of your fonts. <a href="https://www.w3.org/Style/Examples/007/units.en.html">web style sheets CSS tips &amp; tricks</a></li>
<li>Avoid any manual spacing. particularly manual spacing inside Math elements. (\!, hspace, vspace, hfill)</li>
<li>manual positioning (cover pages, pgf drawing across page), Triggery with callers, hidden cross-referencing.</li>
<li>anything that hard codes line breaks, spacings, line length, white spacings etc. because if you want to go to flexible outline and flexible layout all of these things are just a nightmare to get rid of. And sometimes it just screwed up entire conversion process.</li>
<li>Custom counters and items. Where you change how the item looks like. Because all of these converters actually don't know how to deal with that.</li>
<li>In Math Mode: avoid too much mixing. You can mix text in math mode, but you can nest so deeply that ultimately it all breaks down. If you have text inside maths then who is going to render that.</li>
<li>Avoid punctuation near mathematical elements. Mathematicians love to do that but it's still a nightmare.</li>
</ol>
<h2 id="tex-tips-what-to-avoid">TeX tips: what to avoid</h2>
<ul class="incremental">
<li>color</li>
<li>rules-based constructs</li>
<li>generated pictures, pstricks, tikz</li>
<li>but standalone conversion can work</li>
<li>custom counters (e.g., lists)</li>
<li>custom items (\item[…])</li>
<li>hidden crossrefs (question mark question mark question mark–question mark question mark question mark etc.)</li>
<li>hardcoded linebreaks</li>
<li>hardcoded linelengths</li>
<li>hardcoded whitespace</li>
<li>avoid hacking layout using TeX (a little CSS goes a long way)</li>
</ul>
<h2 id="tips-for-math-mode">Tips for math mode</h2>
<ul class="incremental">
<li>custom macros: usually as pass-through, i.e build mathjax config or extension necessary</li>
<li>example: <a href="https://github.com/simurgh9/homework">sty file with mathjax extension</a></li>
<li>avoid mixing text and math mode, e.g., subequations, intertext etc.
<ul class="incremental">
<li>(complex) text mode inside math mode.</li>
<li>Parboxes etc inside math mode</li>
</ul></li>
<li>avoid large tables in math mode (consider tabular)</li>
<li>avoid long inline equations (no linebreaks)</li>
<li>auto aligned environments can surprise
<ul class="incremental">
<li>e.g., multline (without max-width on container)</li>
</ul></li>
<li>auto-numbering support varies</li>
<li>punctuation near math</li>
</ul>
<h1 id="authoring-for-the-web">Authoring for the Web</h1>
<ul class="incremental">
<li>Stop thinking "print only"
<ul class="incremental">
<li>You are no longer bound to a paper size</li>
<li>Spacing should be flexible, colors can change</li>
</ul></li>
<li>Reflow vs Pagination
<ul class="incremental">
<li>Do not assume pages for referencing, positioning, etc.</li>
<li>Graphics, tables, images might be in different positions</li>
</ul></li>
<li>Size really matters
<ul class="incremental">
<li>Content can be viewed on various form factors</li>
<li>Make sure it displays fine even on extreme zoom</li>
</ul></li>
<li>Remember: There might be more Than one output format</li>
</ul>
<p class="arialFont">Note: That does not mean we want you to change your authoring workflow!</p>
<h1 id="other-formats">Other Formats</h1>
<p class="arialFont">What we have done so far is effectively source to web, which in many ways is easy. First of all you got the source file, which gives you most information possible by the document, and you've got most currently available flexible canvas to paint or to draw on your document which is web.<br />
What about other sources, which might be harder. Sources as not necessarily authors sources as well as targets which are different on web.</p>
<h1 id="taxonomy-of-sources">Taxonomy of Sources</h1>
<p class="arialFont">The sources I wanna briefly go to in this part of lecture first one is normally called Retro-digitized. These are the sources which comes from originally printed material, then being digitised in some way, in order to make them available as a file or somewhere via the web. e.g. Scanned, images, electronic documents with scanned images.<br />
The second kind of taxonomy is born digital. Born digital means those are the documents which are actually generated from digital sources, however the source is no longer available to us.<br />
Finally Born Accessible documents are effective documents as we've seen them, we have the sources, or at least the documents are created in a way that they contain everything, that allows us to make them accessible.</p>
<h2 id="retro-digitized">Retro-digitized</h2>
<p class="arialFont">These are generally historical manuscripts runs of journals as well as old books etc. The way they are being sourced is usually through some sort of big organisation like a National library, or publishers do retro-digitised scanned things in a bigger rounds (Google books is also an example), and then make them available as some sort of electronic format. Most of the times these are single images or pdf containing single images of a digitised version.<br />
<a href="https://www.jstor.org/">JSTOR</a> is a classic system where you have a lot of old Retro-digitized documents. You can have directly access via account or there is also access to some of these via program for data research. Let's browse by subject, let's pick one of those mathematics journal, obviously all this is purely image even if you download it as a PDF. There is no content available for you to use. The question now is what you gonna do? If there is no content available for us to use? Well there is various ways to do these things, one common way is using optical character recognition(OCR) program. That means we go from image to some electronic representation, trying to find out where are the characters there, what are the words in a document, then simply try to put together the original content of the document which we have scanned. That is often very difficult, in particular historical documents. Therefore there are various ways not only automating that but also kind of try to proof read and add some corrections to the transcriptions. For instance there is a program called <a href="https://www.zooniverse.org/">Zooniverse</a>, it's a way in order to crowd source information from people primarily via identifying things in images but also transcribe the elements on pages of historical document. One of their flagship project was "weather chart from 1914 to 1980", via various scan sources of weather reports during World War I. And they currently have same for World War II. So there are weather reports which effectively huge tables containing data for every hour of the day at a particular vicinity in longitude and latitude, which is primarily gathered by submarines and different weather ships and so on. It was very successful for World War I. For World War II they are currently at 4%. Actually it will still take a while until people have transcribe that properly and corrected some of their recognition.</p>
<h1 id="what-about-math">What about Math</h1>
<p class="arialFont">One of the problems is that some of these systems works fairly well with regular text. Even when you buy a scanner you normally get a piece of software with that, which does basic OCR for you. It's particularly difficult for mathematical detection and why that is the case? well, because it's simply not just a regular text, there is a couple of artefacts which makes it difficult.<br />
First of all it's more difficult to find where math is in a scanned page, it is more difficult to analyse what the real layout of it is,<br />
you can analyse quite quickly what are single lines, you can analyse quite well what is paragraph, what is header, but finding out where the Math is, what's the size of maths, does it have a label, and then what is actual composition of mathematical element is very very difficult. That has not only to do with dictionaries where you can look things up. Which doesn't allow you to do some sort of secondary or higher order recognition, as you can do for normal texts, for the normal texts you can recognise characters, you can recognise distances between words and you might be able to find sentences, then you can have a higher order recognition running over that again and saying, Ok, well, if we know for an instance this particular piece of writing is in English, then I can start looking things on a dictionary, possibly cross compiling words, which might have errors in them, and thereby do some sort of error correction on particular characters which might have been mis-recognised. In mathematics that is practically impossible. Because there is no dictionaries. There's many different fonts. There's different scripts used… and so on…. All the usual problems, that already make things hard for us, to make things accessible. It's even worse when you talk about OCR.<br />
So What are the possibilities?<br />
</p>
<h1 id="ocr-systems">OCR Systems</h1>
<p class="arialFont">Well, There's bunch of generic OCR systems out there you can use. Which generally do not do good job.<br />
so the most commonly used is for instance <a href="https://pdf.abbyy.com/">Abby Fine Reader</a>, it's a proprietary system and it has support for some special fonts. germafactor fonts, black letter fonts or greek character sets as well as serelic fonts which are often used in math documents. However when it comes to complex layout of mathematics, it's not particularly accurate.<br />
<a href="https://github.com/tesseract-ocr/tesseract">Tesseract</a> which is now maintained by Google and was part of Google book project as well.<br />
Here is another system called <a href="https://en.wikipedia.org/wiki/GOCR">GOCR</a> which is easily available. Unfortunately it doesn't even get the header right. It's even worse.<br />
All of these are quite atrocious what you get as a result. You don't get any of the special characters recognised, so they are effectively unusable.<br />
What else can we do there,<br />
Well, there is one system out there, which has been developed for more than 20 years, actually specialised in Math OCR, that's called <a href="http://www.inftyproject.org/en/index.html">Infty</a>. Unfortunately Infty only runs on Windows.</p>
<ul class="incremental">
<li><a href="https://www.inftyreader.org/">Full document analysis</a></li>
</ul>
<p class="arialFont">they can produce all kinds of different output formats,e.g. TeX, IML (Infty Markup Language), XHTML. The one we are looking now is XHTML page, and XHTML page looks actually quite good, so, much text is in there, the math is there, the problem might, the math doesn't display is because it's XHTML in HTML browser. If we have look at those elements, these are actually Math ML elements, so if we check MathJax in the page it should actually looks quite nice. Obviously above document is the demo document they have on website, and reality is probably not quite as is as fantastic results.<br />
So this is one type of OCR system effectively working on full-page OCR systems. Other things you can have is, what I would refer as snapshotting.</p>
<h1 id="snapshotting">Snapshotting</h1>
<p class="arialFont">What is snapshotting ?<br />
The idea there is you kind of make a isolated observation of a particular element which you know is a mathematics. Crop that formula, then tried to do OCR from that. There are number of systems out there which do that.</p>
<ul class="incremental">
<li><a href="https://mathpix.com/">Mathpix Snip</a></li>
</ul>
<p class="arialFont">It gives me latex formula, translation from the original latex and that's actually pretty good. It recognised entire formula that we've just took from the page which we downloaded from the internet. This is really really nice page in a way! Because it's a well designed PDF document, which has clearly been compiled from latex. Let's have a look at older document, earlier document we've opened from JSTOR, let's try same thing, taking snapshot, and see what happens, what we get in terms of OCR and latex, so the formula for instance is pretty much there, but math symbol Chi recognised as a superscript theta, But otherwise everything seems quite alright.</p>
<ul class="incremental">
<li><p class="arialFont"><a href="https://www.texthelp.com/products/equatio/">EquatIO</a></p>
<p class="arialFont">The nice thing about EquatIO is you can install it inside your browser environment. Meaning that you can now simply run EquatIO from web browser and it opens up a toolbar at the bottom of your screen. and now we can snip out one of these things,<br />
</p></li>
</ul>
<p class="arialFont">let's start with the easy one, it could read out so you can hear now, For those who can't see what we recognised on slides.<br />
Let's try with different document, again same trickery here. Let's do this, so it reads out nicely as well, so again that was all being done with the OCR.<br />
And let's now further final attempt, let's try one of those old paper from 1929, again let's get EquatIO going. Right! That recognised it quite well! With the one exception, that is, this is probably difficult to see, here is probably 6 it's not a small letter "b". But in general it recognised things quite well.<br />
Why it's easier to do in isolation? Because you know it's mathematics, you kind of concentrate on the layout exclusively, you don't have too worry much about the surrounding text.<br />
Now let's try with the surrounding text as well, now you notice that it has misrecognised.<br />
EquatIO has a free version which anybody can install, and then it has a premium version which allows you to do speech recognition and Speech input, I want to show you that next weak, some point in speech input.</p>
<h1 id="born-digital">Born Digital</h1>
<p class="arialFont">Born digital effectively means that you have the digital document which has been compiled from some source, but the sources are not available anymore or at least they are not available to you, and not available to you at that right moment where you need to find out something about document, i.e. making it accessible.<br />
The general use case is you have a PDF document which has been compiled from source, something like latex, word, something else, and now you want to make it accessible, unfortunately you don't get to the actual source, therefore you can't just convert, you need to somehow get to the things inside PDF document. Obviously that doesn't only apply for the PDF documents, but there's other document formats like Rich text format, which was proprietary format by Microsoft. They don't really supported anymore, because they've also moved towards PDF. Postscript is precursor to PDF, of course which was primarily for the printers only. but all of these can be converted pretty much losslessly to the PDF. All the content they contained can be converted into PDF.</p>
<p class="arialFont">What if PDF is the only source?<br />
Well, there is a couple of ways how to make it accessible. The easiest one is for instance, Acrobat Reader already offers you ways of just reading it out directly. And it often works with multiple screen readers, straight out of the box.<br />
There are ways of translating things inside browsers, for instance, ChromeVox is used often to integrate, which simply transforms PDF in some sort of web document.<br />
Now the problem is, of course is usual, most of these tools works only for pure text, where they don't necessarily work are, for more complex text, where you have problem for the reading order, for instance if you have multiple column elements and if you have column spanning element, that often break these tools.<br />
If you don't have alt text for images, where should it come from? That also will be ignored, headers and footers can interfere, all of these things can be quite difficult.<br />
Now the problem is as soon as if you have any more complex content, i.e. math content as well as other things, then you can't really work with these PDF documents and these standard PDF readers alone. Unfortunately it's very little understood problem. and most people work with PDFs.<br />
Why can't we just get Maths for instance in a PDF document, because in many ways it's not there! and why it's not there, well, because the way PDF documents is structured, for those who don't know, it's in terms of arranging things along a baseline. and you just effectively have a baseline, on which you arrange characters, and these characters are arranged with particular base points, and you don't have really the information about what the character is, necessarily, or, the character is actually drawn on the canvas of the printed output, or on the screen.<br />
</p>
<h1 id="some-solutions">Some solutions</h1>
<ul class="incremental">
<li>Maxtract system (2008)</li>
<li>Full content extraction</li>
<li>Grammatical approach at PDF reconstruction</li>
<li>Very limited in terms of PDF versions it could handle</li>
<li>Current Ravi Project at IIT:
<ul class="incremental">
<li>Full extraction for client side rendering</li>
<li>Comprehensive approach</li>
<li>Reuses the good part of Maxtract</li>
</ul></li>
<li><a href="https://inftyproject.org/">Infty</a> system has implemented some of the Maxtract ideas</li>
<li><a href="http://apricot.cis.ibaraki.ac.jp/PDFtools/">Akio Fujiyoshi's Lab</a> has some nice solutions</li>
</ul>
<h1 id="born-accessible">Born Accessible</h1>
<p class="arialFont">Conversion to formats that are in principle accessible</p>
<ul class="incremental">
<li>PDF documents</li>
<li>ePub and similar formats, like Daisy</li>
<li>Web documents (as discussed in detail)</li>
</ul>
<h2 id="pdf-documents">PDF documents</h2>
<ul class="incremental">
<li>PDF can be made accessible, there is even a version: PDF/UA
<ul class="incremental">
<li>Requires a lot of "goodwill" by authors</li>
<li>Some tools are more suitable for generating accessible PDFs</li>
</ul></li>
<li>Word good, LaTeX not
<ul class="incremental">
<li>There are a number of tools for accessibility checking</li>
</ul></li>
<li>Some free
<ul class="incremental">
<li>Acrobat Pro is proprietary and not free</li>
</ul></li>
</ul>
<h2 id="generating-accessible-pdf">Generating accessible PDF</h2>
<ul class="incremental">
<li>Important: Reading order, Alt Texts, Header nesting</li>
<li>Word can generate PDF/UA without Math support</li>
<li>LaTeX has very poor support for PDF/UA</li>
<li>Adobe Acrobat Pro can help adding accessibility</li>
<li>Alternatively consider a pandoc workflow via Word</li>
<li>LaTeX is good for Maths but not for structure</li>
</ul>
<h2 id="pdf-current-state">PDF: Current state</h2>
<p class="arialFont">No generator for fully accessible PDF.</p>
<ul class="incremental">
<li>Fixing Accessibility issues is
<ul class="incremental">
<li>Time consuming</li>
<li>Often repetitive</li>
<li>Only work well in Acrobat Pro (proprietary + not free)</li>
</ul></li>
<li>PDF has multiple layers to hide additional information or alternative formats
<ul class="incremental">
<li>Poorly supported</li>
<li>No flexible reflow</li>
</ul></li>
</ul>
<h2 id="epubs">EPubs</h2>
<ul class="incremental">
<li>Format is close to HTML5</li>
<li>Same techniques as for our web documents apply</li>
<li>Some issues due to XHTML handling: namespaces, etc.</li>
<li>Epub readers very greatly
<ul class="incremental">
<li>provision of MathJax for Math</li>
<li>SVG for Diagrams</li>
<li>Javascript for accessibility</li>
</ul></li>
</ul>
<p class="arialFont">Let's have a look at the <a href="http://diagramcenter.org/diagram-reports/diagram-2020-report/multimodal-stem-documents.html#math-braille">diagram report</a> and <a href="chrome-extension://jhhclmfgfllimlhabjkgkeebkbiadflb/reader.html">Test with EPub reader</a></p>
<h2 id="other-alternative-formats-braille">Other Alternative Formats: Braille</h2>
<p class="arialFont">Source: LaTeX in <a href="https://pretextbook.org/">PreTeXt format</a><br />
Target: embossed Braille</p>
<ul class="incremental">
<li>PreTeXt is an XML markup with LaTeX for math.</li>
<li>PreTeXt books are translated automatically into Braille with
<ul class="incremental">
<li>Liblouis for the text</li>
<li>MathJax for formulas using SRE's Nemeth translation</li>
</ul></li>
<li>Multistep translation pipeline server-side using MathJax</li>
<li>Current pipeline is mainly a prototype</li>
<li>Tactile graphics still done primarily manually</li>
<li>Project with the NFB, PreTeXt and AIM</li>
</ul>
<h2 id="outlook">Outlook</h2>
<ul class="incremental">
<li>Diagrams</li>
<li>Sonfication</li>
<li>Advanced content</li>
</ul>

</body>
</html>